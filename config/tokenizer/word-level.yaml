model:
  _target_: tokenizers.models.WordLevel
  unk_token: "<unk>"
pre_tokenizer:
  _target_: tokenizers.pre_tokenizers.Whitespace
trainer:
  _target_: tokenizers.trainers.WordLevelTrainer
  min_frequency: 2
  special_tokens:
    - ${tokenizer.model.unk_token}
    - "<eos>"
output_file: models/tokenizer/word-level.json