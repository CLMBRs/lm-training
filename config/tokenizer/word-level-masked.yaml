model:
  _target_: tokenizers.models.WordLevel
  unk_token: "<unk>"
pre_tokenizer:
  _target_: tokenizers.pre_tokenizers.Whitespace
trainer:
  _target_: tokenizers.trainers.WordLevelTrainer
  min_frequency: 1
  special_tokens:
    - ${tokenizer.model.unk_token}
    - "<eos>"
    - "<pad>"
    - "<MASK>"